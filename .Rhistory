geom_point() +
geom_smooth()
data.frame(x, y) -> df
library(boot)
df <- df %>%
mutate(x_sq = x^2,
x_cube = x^3,
x_4 = x^4)
reg1 <- glm(y ~ x, data = df)
reg2 <- glm(y ~ x + x_sq, data = df)
reg3 <- glm(y ~ x + x_sq + x_cube, data = df)
reg4 <- glm(y ~ x + x_sq + x_cube + x_4, data = df)
reg1CV <- boot::cv.glm(df, reg1)
reg2CV <- boot::cv.glm(df, reg2)
reg3CV <- boot::cv.glm(df, reg3)
reg4CV <- boot::cv.glm(df, reg4)
reg1CV$delta[2]
reg2CV$delta[2]
reg3CV$delta[2]
reg4CV$delta[2]
a1 <- anova(reg1, reg2, reg3, reg4, test = "Chisq")
a1
set.seed(12)
reg1 <- glm(y ~ x, data = df)
reg2 <- glm(y ~ x + x_sq, data = df)
reg3 <- glm(y ~ x + x_sq + x_cube, data = df)
reg4 <- glm(y ~ x + x_sq + x_cube + x_4, data = df)
reg1CV <- boot::cv.glm(df, reg1, K = 10)
reg2CV <- boot::cv.glm(df, reg2, K = 10)
reg3CV <- boot::cv.glm(df, reg3, K = 10)
reg4CV <- boot::cv.glm(df, reg4, K = 10)
reg1CV$delta[2]
reg2CV$delta[2]
reg3CV$delta[2]
reg4CV$delta[2]
default <- ISLR2::Default
set.seed(123)
training_pct <- .6
training <- sample(nrow(default), floor(training_pct*nrow(default)))
logreg <- glm(default ~ income + balance + student, family = "binomial",
data = default, subset = training)
summary(logreg)
predictions_log <- predict(logreg, default[-training,], type="response")
predictions <-  rep("No", dim(default[-training, ])[1])
predictions[predictions_log > 0.5] = "Yes"
table(predictions, default[-training, ]$default)
accuracy <- (3853 + 41) / (3853 + 93 + 13 + 41)
1 - accuracy
#removing student
logreg <- glm(default ~ income + balance, family = "binomial",
data = default, subset = training)
#summary(logreg)
predictions_log <- predict(logreg, default[-training,], type="response")
predictions <-  rep("No", dim(default[-training, ])[1])
predictions[predictions_log > 0.5] = "Yes"
table(predictions, default[-training, ]$default)
accuracy <- (3853 + 42) / (3853 + 92 + 13 + 42)
1 - accuracy
logreg <- glm(default ~ income + balance + student, family = "binomial",
data = default)
logregCV <- boot::cv.glm(data = default, glmfit = logreg)
logregCV$delta[2] #error rate
# LOOCV, removing student
logreg <- glm(default ~ income + balance, family = "binomial",
data = default)
logregCV <- boot::cv.glm(default, logreg)
logregCV$delta[2] #error rate
logreg <- glm(default ~ income + balance + student, family = "binomial",
data = default)
logregCV <- boot::cv.glm(default, logreg, K = 100)
logregCV$delta[2] #error rate
# removing student, k = 100
logreg <- glm(default ~ income + balance, family = "binomial",
data = default)
logregCV <- boot::cv.glm(default, logreg, K = 100)
logregCV$delta[2] #error rate
# student, k = 1,000
logreg <- glm(default ~ income + balance + student, family = "binomial",
data = default)
logregCV <- boot::cv.glm(default, logreg, K = 1000)
logregCV$delta[2] #error rate
# no student, k = 1,000
logreg <- glm(default ~ income + balance, family = "binomial",
data = default)
logregCV <- boot::cv.glm(default, logreg, K = 1000)
logregCV$delta[2] #error rate
default <- ISLR2::Default %>%
drop_na(student, income, balance, default)
euclidean <- function(a, b) sqrt(sum((a - b)^2))
euclidean(-2,0)
euclidean(-4,4)
0^2
sqrt(8)
sqrt(5)
sqrt(1)
4+89
5+9
4+9
sqrt(13)
# Parameters
x_div <- 20
x_no_div <- 5
sigma_sq <- 25
p_dividend <- 0.7
x <- 12
# Probability density function of the normal distribution
pdf <- function(x, mean, variance) {
1 / sqrt(2 * pi * variance) * exp(-(x - mean)^2 / (2 * variance))
}
# Probability of getting X = x given that the company issued a dividend
p_x_given_dividend <- pdf(x, x_div, sigma_sq)
# Total probability of getting X = x
p_x <- p_x_given_dividend * p_dividend + pdf(x, x_no_div, sigma_sq) * (1 - p_dividend)
# Probability of a company issuing a dividend given that X = x
p_dividend_given_x <- p_x_given_dividend * p_dividend / p_x
p_dividend_given_x
data.table(x = c(1,2))
x <- (0,0,2,3,5)
x <- c(0,0,2,3,5)
library(tidyverse)
df <- data(mpg)
df %>%
ggplot(aes(x = cty, y = disp)) +
geom_smooth()
df <- ggplot2::mpg
df %>%
ggplot(aes(x = cty, y = disp)) +
geom_smooth()
df %>%
ggplot(aes(x = cty, y = displ)) +
geom_smooth()
df %>%
ggplot(aes(x = cty, y = displ)) +
geom_point()
df %>%
ggplot(aes(x = cty, y = displ)) +
geom_point() +
geom_smooth()
df %>%
ggplot(aes(y = cty, x = displ)) +
geom_point() +
geom_smooth()
lm_cty <- lm(cty ~ displ, data = df)
summary(lm_cty)
saturated <- lm(cty ~ as.factor(displ), data = df)
# creating the saturated model
saturated <- lm(cty ~ as.factor(displ), data = df)
reduced <- lm(cty ~ displ, data = df)
anova(reduced, saturated)
#creating displ^2
df <- df %>% mutate(displ_2 = displ^2)
lm_cty2 <- lm(cty ~ displ + displ_2, data = df)
summary(lm_cty2)
anova(lm_cty, lm_cty2)
# training
training_pct <- .5
training <- sample(nrow(df), floor(training_pct*nrow(df)))
set.seed(123)
# training
training_pct <- .5
training <- sample(nrow(df), floor(training_pct*nrow(df)))
predictions_linear <- predict(lm_cty, df[-training,], type="response")
set.seed(123)
# training
training_pct <- .5
training <- sample(nrow(df), floor(training_pct*nrow(df)))
predictions_linear <- predict(lm_cty, df[-training,], type="response")
set.seed(123)
# training
training_pct <- .5
training <- sample(nrow(df), floor(training_pct*nrow(df)))
lm_cty <- lm(cty ~ displ, subset = training, data = df)
predictions_linear <- predict(lm_cty, df[-training,], type="response")
predictions_linear
LOOCV_lm <- glm(cty ~ displ,data = df)
set.seed(123)
LOOCV_lm <- glm(cty ~ displ,data = df)
lmCV <- boot::cv.glm(data = df, glmfit = LOOCV_lm)
lmCV$delta[2][1] #error rate
set.seed(123)
kfold_lm <- glm(cty ~ displ,data = df)
kCV <- boot::cv.glm(data = df, glmfit = kfold_lm, K = 10)
kCV$delta[2][1] #error rate
set.seed(123)
n <- nrow(df)
Z <- training
rmse <- vector(mode = "double", length = 10)
for (k  in seq_along(rmse)) {
reg <- lm(cty ~ displ, data = df, subset = Z) # training data
Yhat <- predict(reg, newdata = df[-Z,]) # test data
Ytest = df$cty[-Z] # test data
rmse[[k]] <- sqrt(mean(Yhat - Ytest)^2)
}
rmse <- vector(mode = "double")
for (k  in seq_along(rmse)) {
reg <- lm(cty ~ displ, data = df, subset = Z) # training data
Yhat <- predict(reg, newdata = df[-Z,]) # test data
Ytest = df$cty[-Z] # test data
rmse[[k]] <- sqrt(mean(Yhat - Ytest)^2)
}
rmse <- vector(mode = "double", length = nrow(Z))
length(Z)
rmse <- vector(mode = "double", length = 117)
for (k  in seq_along(rmse)) {
reg <- lm(cty ~ displ, data = df, subset = Z) # training data
Yhat <- predict(reg, newdata = df[-Z,]) # test data
Ytest = df$cty[-Z] # test data
rmse[[k]] <- sqrt(mean(Yhat - Ytest)^2)
}
rmse
which.min(rmse)
Yhat <- predict(reg, newdata = df[-Z,], type="response") # test data
rmse <- vector(mode = "double", length = 117) # length of training
for (k  in seq_along(rmse)) {
reg <- lm(cty ~ displ, data = df, subset = Z) # training data
Yhat <- predict(reg, newdata = df[-Z,], type="response") # test data
Ytest = df$cty[-Z] # test data
rmse[[k]] <- sqrt(mean(Yhat - Ytest)^2)
}
which.min(rmse)
mean(rmse)
which.min(rmse)
glimpse(df)
# make class factor
df <- df %>% mutate(class = as.factor(class))
glimpse(df)
set.seed(123)
# make class factor
df <- df %>% mutate(class = as.factor(class))
LOOCV_lm2 <- glm(cty ~ displ + class,data = df)
lmCV2 <- boot::cv.glm(data = df, glmfit = LOOCV_lm2)
set.seed(123)
# make class factor
df <- df %>% mutate(class = as.factor(class))
LOOCV_lm2 <- glm(cty ~ displ + class,data = df)
lmCV2 <- boot::cv.glm(data = df, glmfit = LOOCV_lm2)
lmCV2$delta[2][1] #error rate
lmCV$delta[2][1] #error rate w out class
lmCV2$delta[2][1] #error rate with class
lmCV2$delta #error rate with class
lmCV$delta #error rate w out class
df$class
x <- c(0,0,2,3,3,5)
improvement <- c("N","Y","N","Y","Y","Y" )
as_tibble(dose, improvement)
dose <- c(0,0,2,3,3,5)
improvement <- c("N","Y","N","Y","Y","Y" )
as_tibble(dose, improvement)
data.frame(dose, improvement)
train <- data.frame(dose, improvement)
dose <- c(0,0,1,2,3,4)
improvement <- c("N","N","Y","Y","N","Y" )
test <- data.frame(dose, improvement)
MASS::qda(improvement ~ dose, data = Weekly[training,])
bind_rows(train, test)
bind_rows(train, test)
d1 <- bind_rows(train, test)
MASS::qda(improvement ~ dose, data = d1[train,])
dose <- c(0,0,2,3,3,5)
improvement <- c("N","Y","N","Y","Y","Y" )
train <- data.frame(dose, improvement)
dose <- c(0,0,1,2,3,4)
improvement <- c("N","N","Y","Y","N","Y" )
test <- data.frame(dose, improvement)
d1 <- bind_rows(train, test)
MASS::qda(improvement ~ dose, data = d1[train,])
MASS::qda(improvement ~ dose, data = d1[train])
MASS::qda(improvement ~ dose, data = train)
MASS::lda(improvement ~ dose, data = train)
predictions <- predict(lda_result, test)
lda_result <- MASS::lda(improvement ~ dose, data = train)
predictions <- predict(lda_result, test)
table(predictions$class, test$improvement)
predictions <- predict(lda_result, test)
prediction
predictions
predictions$x
predictions$class
5/6
x <- 0
prior_good <- .5
prior_bad <- 1 - prior_good
good <- prior_good * (1/sqrt(2.5)) * exp(-(x - 3)^2 / (2 * 2.5))
round(good, 3)
0+0+5+3+5
13/6
c(0,0,2,3,3,5)
x <- c(0,0,2,3,3,5)
sd(x)
x <- c(0,3,3,5)
x/4
0+3+3+5
11/4
sd(0+3+3+5)
c(0,3,3,5) -> x
sd(x)
c(0,2) -> x
sd(x)
top <- (.5)*((1)/2.061*sqrt(2*pi)exp((-(dose-2.75)^2)/(2*2.061)^2))
(.5)*((1)/2.061*sqrt(2*pi)exp((-(dose-2.75)^2)/(2*2.061)^2))
dose = 0
(.5)*((1)/2.061*sqrt(2*pi)exp((-(dose-2.75)^2)/(2*2.061)^2))
.5 * (1/sqrt(2.06)) * exp(-(dose - 3)^2 / (2 * 2.061))
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
dose = 0
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
x / (x+y)
dose = 1
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
x / (x+y)
dose = 2
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
x / (x+y)
dose = 3
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
x / (x+y)
dose = 5
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
x / (x+y)
dose = 4
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
x / (x+y)
library(tidyverse)
dose = 4
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
x / (x+y)
df <- ggplot2::mpg
df %>%
ggplot(aes(y = cty, x = displ)) +
geom_point() +
geom_smooth()
lm_cty <- lm(cty ~ displ, data = df)
summary(lm_cty)
# creating the saturated model
saturated <- lm(cty ~ as.factor(displ), data = df)
reduced <- lm(cty ~ displ, data = df)
anova(reduced, saturated)
#creating displ^2
df <- df %>% mutate(displ_2 = displ^2)
lm_cty2 <- lm(cty ~ displ + displ_2, data = df)
summary(lm_cty2)
anova(lm_cty, lm_cty2)
set.seed(123)
training_pct <- .5
training <- sample(nrow(df), floor(training_pct*nrow(df)))
set.seed(123)
n <- nrow(df)
Z <- training
rmse <- vector(mode = "double", length = 117) # length of training
for (k  in seq_along(rmse)) {
reg <- lm(cty ~ displ, data = df, subset = Z) # training data
Yhat <- predict(reg, newdata = df[-Z,], type="response") # test data
Ytest = df$cty[-Z] # test data
rmse[[k]] <- sqrt(mean(Yhat - Ytest)^2)
}
which.min(rmse)
set.seed(123)
LOOCV_lm <- glm(cty ~ displ,data = df)
lmCV <- boot::cv.glm(data = df, glmfit = LOOCV_lm)
lmCV$delta[2][1] #error rate
set.seed(123)
kfold_lm <- glm(cty ~ displ,data = df)
kCV <- boot::cv.glm(data = df, glmfit = kfold_lm, K = 10)
kCV$delta[2][1] #error rate
set.seed(123)
# make class factor
df <- df %>% mutate(class = as.factor(class))
LOOCV_lm2 <- glm(cty ~ displ + class,data = df)
lmCV2 <- boot::cv.glm(data = df, glmfit = LOOCV_lm2)
lmCV2$delta #error rate with class
lmCV$delta #error rate w out class
set.seed(123)
# make class factor
df <- df %>% mutate(class = as.factor(class))
lm2 <- glm(cty ~ displ + class,data = df)
lmCV2 <- boot::cv.glm(data = df, glmfit = lm2)
summary(lmCV2)
summary(lm2)
summary(lm2)
glm(formula = cty ~ displ + class + class:displ, data = df)
summary(glm(formula = cty ~ displ + class + class:displ, data = df))
df %>%
filter(class == "minivan")
df %>%
ggplot(aes(x = displ, y = cty, color = class)) +
geom_point()
dose = 0
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
x / (x+y)
dose = 1
x <- .5 * (1/sqrt(2.06)) * exp(-(dose - 2.75)^2 / (2 * 2.061))
y <- .5 * (1/sqrt(1.414)) * exp(-(dose - 1)^2 / (2 * 1.414))
x / (x+y)
write_csv(trump, "trump_no_retweets.csv")
write.csv(trump, "trump_no_retweets.csv")
read_csv("OneDrive - american.edu/S2/DATA-441/nlp-project/trump_tweets.csv") %>%
filter(is_retweet == "FALSE") %>%
filter(datetime > "2019-12-31") %>%
select(text, favorites, retweets, datetime, id) -> trump
library(tidyverse)
read_csv("OneDrive - american.edu/S2/DATA-441/nlp-project/trump_tweets.csv") %>%
filter(is_retweet == "FALSE") %>%
filter(datetime > "2019-12-31") %>%
select(text, favorites, retweets, datetime, id) -> trump
write.csv(trump, "trump_no_retweets.csv")
setwd("/Users/michaellewis/Library/CloudStorage/OneDrive-american.edu/S2/DATA-441/nlp-project")
read_csv("trump_tweets.csv") %>%
filter(is_retweet == "FALSE") %>%
filter(datetime > "2019-12-31") %>%
select(text, favorites, retweets, datetime, id) -> trump
write.csv(trump, "trump_no_retweets.csv")
View(trump)
`row.names<-.default`(trump, NULL)
View(trump)
write.csv(trump, "trump_no_retweets.csv")
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp > "2019-12-31")
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01")
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp)
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp) %>%
rename("text":"tweet")
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp) %>%
rename("tweet":"text")
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp) %>%
rename("text":"tweet")
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp)
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp) %>%
mutate(text = tweet) %>%
select(-tweet)
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp) %>%
mutate(text = tweet) %>%
select(-tweet) %>%
select(text, likes, retweets, timestamp) %>%
`row.names<-.default`(trump, NULL)
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp) %>%
mutate(text = tweet) %>%
select(-tweet) %>%
select(text, likes, retweets, timestamp)
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp, id) %>%
mutate(text = tweet) %>%
select(-tweet) %>%
select(text, likes, retweets, timestamp, id)
read_csv("trump_tweets.csv") %>%
filter(is_retweet == "FALSE") %>%
filter(datetime > "2019-12-31") %>%
mutate(likes = favorites,
timestamp = datetime) %>%
select(text, likes, retweets, timestamp, id)
`row.names<-.default`(trump, NULL)
read_csv("trump_tweets.csv") %>%
filter(is_retweet == "FALSE") %>%
filter(datetime > "2019-12-31") %>%
mutate(likes = favorites,
timestamp = datetime) %>%
select(text, likes, retweets, timestamp, id) %>%
write.csv("trump_filtered.csv")
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp, id) %>%
mutate(text = tweet) %>%
select(-tweet) %>%
select(text, likes, retweets, timestamp, id) %>%
write.csv("biden_filtered.csv")
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp, id) %>%
mutate(text = tweet) %>%
select(-tweet) %>%
select(text, likes, retweets, timestamp, id)
write.csv(biden, "biden_filtered.csv")
read_csv("JoeBidenTweets.csv") %>%
filter(timestamp >= "2020-01-01") %>%
select(tweet, likes, retweets, timestamp, id) %>%
mutate(text = tweet) %>%
select(-tweet) %>%
select(text, likes, retweets, timestamp, id) -> biden
write.csv(biden, "biden_filtered.csv")
read_csv("trump_tweets.csv") %>%
filter(is_retweet == "FALSE") %>%
filter(datetime > "2019-12-31") %>%
mutate(likes = favorites,
timestamp = datetime) %>%
select(text, likes, retweets, timestamp, id) -> trump
write.csv(trump, "trump_filtered.csv")
