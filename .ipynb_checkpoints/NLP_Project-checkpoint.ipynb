{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42d1503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/michaellewis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/michaellewis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD, FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from nltk.util import ngrams\n",
    "import cgi\n",
    "import nltk\n",
    "import html\n",
    "import readability \n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ac9fb",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9351a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden = pd.read_csv(\"biden_filtered.csv\")\n",
    "trump = pd.read_csv(\"trump_filtered.csv\")\n",
    "biden['author'] = \"Biden\"\n",
    "trump['author'] = \"Trump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919524f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = trump[trump.columns[1:]]\n",
    "biden = biden[biden.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f101a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.concat([biden, trump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b04ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterCleaner:\n",
    "    def __init__(self, df, column):\n",
    "        self.df = df\n",
    "        self.column = column\n",
    "\n",
    "    def decode_xml_entities(self, text):\n",
    "        text = html.unescape(text)\n",
    "        text = str(text)\n",
    "        return text\n",
    "\n",
    "    def clean_text(self, lemmatize=False, stem=False, remove_stopwords=True):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        self.df[self.column] = self.df[self.column].apply(lambda x: str(x))\n",
    "        clean_list = []\n",
    "        for text in self.df[self.column]:\n",
    "            # remove URLs\n",
    "            text = re.sub(r'http\\S+','', text)  \n",
    "\n",
    "            # remove '@' twitter mentions\n",
    "            text = re.sub(r'@[A-Za-z0-9_]+','', text) \n",
    "\n",
    "            # XML to characters\n",
    "            text = self.decode_xml_entities(text)\n",
    "\n",
    "            # lowercase the text\n",
    "            text = text.lower() \n",
    "            words = word_tokenize(text)\n",
    "\n",
    "            clean_words = []\n",
    "\n",
    "            # stemming / lemmatization\n",
    "\n",
    "            for word in words:\n",
    "                if remove_stopwords == True and word in stop_words:\n",
    "                    continue\n",
    "                if lemmatize == True: \n",
    "                    lemmatizer = WordNetLemmatizer()\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "                if stem == True: \n",
    "                    stemmer = PorterStemmer()\n",
    "                    word = stemmer.stem(word)\n",
    "                clean_words.append(word)\n",
    "\n",
    "            clean_text = ' '.join(clean_words)\n",
    "            clean_list.append(clean_text)\n",
    "\n",
    "        if lemmatize:\n",
    "            if remove_stopwords:\n",
    "                self.df[f\"{self.column}_clean_lemmatized_stopwords\"] = clean_list\n",
    "            else:\n",
    "                self.df[f\"{self.column}_clean_lemmatized\"] = clean_list\n",
    "        elif stem:\n",
    "            if remove_stopwords:\n",
    "                self.df[f\"{self.column}_clean_stemmed_stopwords\"] = clean_list\n",
    "            else:\n",
    "                self.df[f\"{self.column}_clean_stemmed\"] = clean_list\n",
    "        else:\n",
    "            if remove_stopwords:\n",
    "                self.df[f\"{self.column}_clean_stopwords\"] = clean_list\n",
    "            else:\n",
    "                self.df[f\"{self.column}_clean\"] = clean_list\n",
    "\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c6f6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>text_clean_lemmatized_stopwords</th>\n",
       "      <th>text_clean_stemmed_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every single human being deserves to be treate...</td>\n",
       "      <td>11574</td>\n",
       "      <td>2423</td>\n",
       "      <td>2020-01-01 18:35:00</td>\n",
       "      <td>1.212442e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>every single human deserves treated dignity . ...</td>\n",
       "      <td>everi singl human deserv treat digniti . every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With just over one month until the Iowa Caucus...</td>\n",
       "      <td>1457</td>\n",
       "      <td>368</td>\n",
       "      <td>2020-01-02 00:01:00</td>\n",
       "      <td>1.212524e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>one month iowa caucus , need hand deck talk fo...</td>\n",
       "      <td>one month iowa caucu , need hand deck talk fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This election is about the soul of our nation ...</td>\n",
       "      <td>44886</td>\n",
       "      <td>10192</td>\n",
       "      <td>2020-01-02 01:05:00</td>\n",
       "      <td>1.212540e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>election soul nation — donald trump poison soul .</td>\n",
       "      <td>elect soul nation — donald trump poison soul .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Every day that Donald Trump remains in the Whi...</td>\n",
       "      <td>9581</td>\n",
       "      <td>2005</td>\n",
       "      <td>2020-01-02 02:07:00</td>\n",
       "      <td>1.212556e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>every day donald trump remains white house put...</td>\n",
       "      <td>everi day donald trump remain white hous put f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a privilege to work with @JulianCastro ...</td>\n",
       "      <td>17156</td>\n",
       "      <td>2284</td>\n",
       "      <td>2020-01-02 16:10:00</td>\n",
       "      <td>1.212768e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>privilege work obama administration , true hon...</td>\n",
       "      <td>privileg work obama administr , true honor tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>Iran never won a war, but never lost a negotia...</td>\n",
       "      <td>303007</td>\n",
       "      <td>57253</td>\n",
       "      <td>2020-01-03 12:44:30</td>\n",
       "      <td>1.213079e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>iran never war , never lost negotiation !</td>\n",
       "      <td>iran never war , never lost negoti !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>Thank you to the @dcexaminer Washington Examin...</td>\n",
       "      <td>35044</td>\n",
       "      <td>9213</td>\n",
       "      <td>2020-01-01 01:03:15</td>\n",
       "      <td>1.212177e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>thank washington examiner . list growing every...</td>\n",
       "      <td>thank washington examin . list grow everi day !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>One of my greatest honors was to have gotten C...</td>\n",
       "      <td>56731</td>\n",
       "      <td>12761</td>\n",
       "      <td>2020-01-01 00:55:01</td>\n",
       "      <td>1.212175e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>one greatest honor gotten choice approved grea...</td>\n",
       "      <td>one greatest honor gotten choic approv great v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>Just signed an order to support the workers of...</td>\n",
       "      <td>176289</td>\n",
       "      <td>36001</td>\n",
       "      <td>2020-10-22 21:04:21</td>\n",
       "      <td>1.319384e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>signed order support worker delphi corporation...</td>\n",
       "      <td>sign order support worker delphi corpor make s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>Suburban women want Safety &amp; Security. Joe Bid...</td>\n",
       "      <td>95169</td>\n",
       "      <td>19545</td>\n",
       "      <td>2020-10-22 18:31:46</td>\n",
       "      <td>1.319346e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>suburban woman want safety &amp; security . joe bi...</td>\n",
       "      <td>suburban women want safeti &amp; secur . joe biden...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9335 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   likes  retweets  \\\n",
       "0     Every single human being deserves to be treate...   11574      2423   \n",
       "1     With just over one month until the Iowa Caucus...    1457       368   \n",
       "2     This election is about the soul of our nation ...   44886     10192   \n",
       "3     Every day that Donald Trump remains in the Whi...    9581      2005   \n",
       "4     It was a privilege to work with @JulianCastro ...   17156      2284   \n",
       "...                                                 ...     ...       ...   \n",
       "6403  Iran never won a war, but never lost a negotia...  303007     57253   \n",
       "6404  Thank you to the @dcexaminer Washington Examin...   35044      9213   \n",
       "6405  One of my greatest honors was to have gotten C...   56731     12761   \n",
       "6406  Just signed an order to support the workers of...  176289     36001   \n",
       "6407  Suburban women want Safety & Security. Joe Bid...   95169     19545   \n",
       "\n",
       "                timestamp            id author  \\\n",
       "0     2020-01-01 18:35:00  1.212442e+18  Biden   \n",
       "1     2020-01-02 00:01:00  1.212524e+18  Biden   \n",
       "2     2020-01-02 01:05:00  1.212540e+18  Biden   \n",
       "3     2020-01-02 02:07:00  1.212556e+18  Biden   \n",
       "4     2020-01-02 16:10:00  1.212768e+18  Biden   \n",
       "...                   ...           ...    ...   \n",
       "6403  2020-01-03 12:44:30  1.213079e+18  Trump   \n",
       "6404  2020-01-01 01:03:15  1.212177e+18  Trump   \n",
       "6405  2020-01-01 00:55:01  1.212175e+18  Trump   \n",
       "6406  2020-10-22 21:04:21  1.319384e+18  Trump   \n",
       "6407  2020-10-22 18:31:46  1.319346e+18  Trump   \n",
       "\n",
       "                        text_clean_lemmatized_stopwords  \\\n",
       "0     every single human deserves treated dignity . ...   \n",
       "1     one month iowa caucus , need hand deck talk fo...   \n",
       "2     election soul nation — donald trump poison soul .   \n",
       "3     every day donald trump remains white house put...   \n",
       "4     privilege work obama administration , true hon...   \n",
       "...                                                 ...   \n",
       "6403          iran never war , never lost negotiation !   \n",
       "6404  thank washington examiner . list growing every...   \n",
       "6405  one greatest honor gotten choice approved grea...   \n",
       "6406  signed order support worker delphi corporation...   \n",
       "6407  suburban woman want safety & security . joe bi...   \n",
       "\n",
       "                           text_clean_stemmed_stopwords  \n",
       "0     everi singl human deserv treat digniti . every...  \n",
       "1     one month iowa caucu , need hand deck talk fol...  \n",
       "2        elect soul nation — donald trump poison soul .  \n",
       "3     everi day donald trump remain white hous put f...  \n",
       "4     privileg work obama administr , true honor tal...  \n",
       "...                                                 ...  \n",
       "6403               iran never war , never lost negoti !  \n",
       "6404    thank washington examin . list grow everi day !  \n",
       "6405  one greatest honor gotten choic approv great v...  \n",
       "6406  sign order support worker delphi corpor make s...  \n",
       "6407  suburban women want safeti & secur . joe biden...  \n",
       "\n",
       "[9335 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc = TwitterCleaner(tweets, 'text')\n",
    "tweets = tc.clean_text(lemmatize = True, stem = False, remove_stopwords = True)\n",
    "tweets = tc.clean_text(lemmatize = False, stem = True, remove_stopwords = True)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52442f1b",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e13879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/michaellewis/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>text_clean_lemmatized_stopwords</th>\n",
       "      <th>text_clean_stemmed_stopwords</th>\n",
       "      <th>sentiment_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every single human being deserves to be treate...</td>\n",
       "      <td>11574</td>\n",
       "      <td>2423</td>\n",
       "      <td>2020-01-01 18:35:00</td>\n",
       "      <td>1.212442e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>every single human deserves treated dignity . ...</td>\n",
       "      <td>everi singl human deserv treat digniti . every...</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With just over one month until the Iowa Caucus...</td>\n",
       "      <td>1457</td>\n",
       "      <td>368</td>\n",
       "      <td>2020-01-02 00:01:00</td>\n",
       "      <td>1.212524e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>one month iowa caucus , need hand deck talk fo...</td>\n",
       "      <td>one month iowa caucu , need hand deck talk fol...</td>\n",
       "      <td>0.6597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This election is about the soul of our nation ...</td>\n",
       "      <td>44886</td>\n",
       "      <td>10192</td>\n",
       "      <td>2020-01-02 01:05:00</td>\n",
       "      <td>1.212540e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>election soul nation — donald trump poison soul .</td>\n",
       "      <td>elect soul nation — donald trump poison soul .</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Every day that Donald Trump remains in the Whi...</td>\n",
       "      <td>9581</td>\n",
       "      <td>2005</td>\n",
       "      <td>2020-01-02 02:07:00</td>\n",
       "      <td>1.212556e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>every day donald trump remains white house put...</td>\n",
       "      <td>everi day donald trump remain white hous put f...</td>\n",
       "      <td>-0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a privilege to work with @JulianCastro ...</td>\n",
       "      <td>17156</td>\n",
       "      <td>2284</td>\n",
       "      <td>2020-01-02 16:10:00</td>\n",
       "      <td>1.212768e+18</td>\n",
       "      <td>Biden</td>\n",
       "      <td>privilege work obama administration , true hon...</td>\n",
       "      <td>privileg work obama administr , true honor tal...</td>\n",
       "      <td>0.9442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>Iran never won a war, but never lost a negotia...</td>\n",
       "      <td>303007</td>\n",
       "      <td>57253</td>\n",
       "      <td>2020-01-03 12:44:30</td>\n",
       "      <td>1.213079e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>iran never war , never lost negotiation !</td>\n",
       "      <td>iran never war , never lost negoti !</td>\n",
       "      <td>0.4071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>Thank you to the @dcexaminer Washington Examin...</td>\n",
       "      <td>35044</td>\n",
       "      <td>9213</td>\n",
       "      <td>2020-01-01 01:03:15</td>\n",
       "      <td>1.212177e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>thank washington examiner . list growing every...</td>\n",
       "      <td>thank washington examin . list grow everi day !</td>\n",
       "      <td>0.5411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>One of my greatest honors was to have gotten C...</td>\n",
       "      <td>56731</td>\n",
       "      <td>12761</td>\n",
       "      <td>2020-01-01 00:55:01</td>\n",
       "      <td>1.212175e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>one greatest honor gotten choice approved grea...</td>\n",
       "      <td>one greatest honor gotten choic approv great v...</td>\n",
       "      <td>0.9060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>Just signed an order to support the workers of...</td>\n",
       "      <td>176289</td>\n",
       "      <td>36001</td>\n",
       "      <td>2020-10-22 21:04:21</td>\n",
       "      <td>1.319384e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>signed order support worker delphi corporation...</td>\n",
       "      <td>sign order support worker delphi corpor make s...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>Suburban women want Safety &amp; Security. Joe Bid...</td>\n",
       "      <td>95169</td>\n",
       "      <td>19545</td>\n",
       "      <td>2020-10-22 18:31:46</td>\n",
       "      <td>1.319346e+18</td>\n",
       "      <td>Trump</td>\n",
       "      <td>suburban woman want safety &amp; security . joe bi...</td>\n",
       "      <td>suburban women want safeti &amp; secur . joe biden...</td>\n",
       "      <td>0.6996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9335 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   likes  retweets  \\\n",
       "0     Every single human being deserves to be treate...   11574      2423   \n",
       "1     With just over one month until the Iowa Caucus...    1457       368   \n",
       "2     This election is about the soul of our nation ...   44886     10192   \n",
       "3     Every day that Donald Trump remains in the Whi...    9581      2005   \n",
       "4     It was a privilege to work with @JulianCastro ...   17156      2284   \n",
       "...                                                 ...     ...       ...   \n",
       "6403  Iran never won a war, but never lost a negotia...  303007     57253   \n",
       "6404  Thank you to the @dcexaminer Washington Examin...   35044      9213   \n",
       "6405  One of my greatest honors was to have gotten C...   56731     12761   \n",
       "6406  Just signed an order to support the workers of...  176289     36001   \n",
       "6407  Suburban women want Safety & Security. Joe Bid...   95169     19545   \n",
       "\n",
       "                timestamp            id author  \\\n",
       "0     2020-01-01 18:35:00  1.212442e+18  Biden   \n",
       "1     2020-01-02 00:01:00  1.212524e+18  Biden   \n",
       "2     2020-01-02 01:05:00  1.212540e+18  Biden   \n",
       "3     2020-01-02 02:07:00  1.212556e+18  Biden   \n",
       "4     2020-01-02 16:10:00  1.212768e+18  Biden   \n",
       "...                   ...           ...    ...   \n",
       "6403  2020-01-03 12:44:30  1.213079e+18  Trump   \n",
       "6404  2020-01-01 01:03:15  1.212177e+18  Trump   \n",
       "6405  2020-01-01 00:55:01  1.212175e+18  Trump   \n",
       "6406  2020-10-22 21:04:21  1.319384e+18  Trump   \n",
       "6407  2020-10-22 18:31:46  1.319346e+18  Trump   \n",
       "\n",
       "                        text_clean_lemmatized_stopwords  \\\n",
       "0     every single human deserves treated dignity . ...   \n",
       "1     one month iowa caucus , need hand deck talk fo...   \n",
       "2     election soul nation — donald trump poison soul .   \n",
       "3     every day donald trump remains white house put...   \n",
       "4     privilege work obama administration , true hon...   \n",
       "...                                                 ...   \n",
       "6403          iran never war , never lost negotiation !   \n",
       "6404  thank washington examiner . list growing every...   \n",
       "6405  one greatest honor gotten choice approved grea...   \n",
       "6406  signed order support worker delphi corporation...   \n",
       "6407  suburban woman want safety & security . joe bi...   \n",
       "\n",
       "                           text_clean_stemmed_stopwords  sentiment_scores  \n",
       "0     everi singl human deserv treat digniti . every...           -0.4019  \n",
       "1     one month iowa caucu , need hand deck talk fol...            0.6597  \n",
       "2        elect soul nation — donald trump poison soul .           -0.5423  \n",
       "3     everi day donald trump remain white hous put f...           -0.5719  \n",
       "4     privileg work obama administr , true honor tal...            0.9442  \n",
       "...                                                 ...               ...  \n",
       "6403               iran never war , never lost negoti !            0.4071  \n",
       "6404    thank washington examin . list grow everi day !            0.5411  \n",
       "6405  one greatest honor gotten choic approv great v...            0.9060  \n",
       "6406  sign order support worker delphi corpor make s...            0.0000  \n",
       "6407  suburban women want safeti & secur . joe biden...            0.6996  \n",
       "\n",
       "[9335 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_score(sentence):\n",
    "    score = analyzer.polarity_scores(sentence)\n",
    "    return score['compound']\n",
    "\n",
    "tweets['sentiment_scores'] = [sentiment_score(sentence) for sentence in tweets['text_clean_lemmatized_stopwords']]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c10d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment score for Biden: 0.17794974376494702\n"
     ]
    }
   ],
   "source": [
    "print(\"Average sentiment score for Biden: \" + str(tweets[tweets['author'] == \"Biden\"]['sentiment_scores'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "798fa147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment score for Trump: 0.1705028870162297\n"
     ]
    }
   ],
   "source": [
    "print(\"Average sentiment score for Trump: \" + str(tweets[tweets['author'] == \"Trump\"]['sentiment_scores'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f8ac51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically the same sentiment score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
